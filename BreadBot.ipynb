{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bread Bot Data Processing\n",
    "\n",
    "This is an experiment with simple visualization using Discord bot commands run on a reasonably active Discord guild. You can read the accompanying blog post [here]().\n",
    "\n",
    "If you've never used a Jupyter notebook before, it's essentially a Markdown document that can run code snippets from various interpreted languages in it\n",
    "(famously Python). To see output from the code snippets, click on one of them and then click \"Run\" from the top.\n",
    "\n",
    "As of now (sadly), the code snippets are stateful, so you need to run them in order of appearance. If something goes wrong, just press the reset button. \n",
    "\n",
    "## Introduction\n",
    "\n",
    "BreadBot, a bot running on ACM @ UCSD's Discord server, has tracked commands run with it by tracking their timestamp, author and channel location every time a command was sent. The data file was initially stored in a JSON file holding only counts, however soon afterwards, the format of the data file was changed to\n",
    "a separated-values file. We will begin by extracting the data and then constructing graphs to visualize the data using interesting graphs.\n",
    "\n",
    "## Data Import\n",
    "\n",
    "SV file with delimiter `:` was used, with header:\n",
    "`timestamp:command:username:channel`\n",
    "\n",
    "First, we import the SV file and check for integrity of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "\n",
    "sns.set()  # Import Seaborn's style, cause it's cool\n",
    "\n",
    "commandCounts = pd.read_csv('commandCount.log', delimiter=':')\n",
    "commandCounts.head(5) # Displays first 5 values from DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using updated format, BreadBot tracked only count of commands in a JSON file with key-value structure as `command:count`, rather than the additional information above. We'll add it to a separate DataFrame with some placeholder data in the other fields to ensure we maintain consistent data.\n",
    "\n",
    "For reference, other placeholder values will be:\n",
    "- `1589814600000`: timestamp (May 18, 2020, 8:10 PM PST, time of announcement of BreadBot count competition)\n",
    "- `other#0001`: username\n",
    "- `ðŸ¤–bot-spam`: channel (after cursory glances, most commands were sent in #bot-spam due to guild rules, so this is sensible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldCommandCounts = pd.DataFrame(columns=['timestamp', 'command', 'username', 'channel'])\n",
    "\n",
    "with open('commandCountOld.json', 'r') as jsonFile:\n",
    "    commandCountsJson = json.load(jsonFile)\n",
    "    for key, value in commandCountsJson.items():\n",
    "        if value == 0: # We'll exclude commands with count 0, since the original JSON kept counts at 0, too\n",
    "            continue\n",
    "        for i in range(value):\n",
    "            # Add this command run to the dataset value times\n",
    "            oldCommandCounts = oldCommandCounts.append({'timestamp': 1589814600000, 'command': key, 'username': 'other#0001', 'channel': 'ðŸ¤–bot-spam'}, \n",
    "                ignore_index=True)\n",
    "\n",
    "oldCommandCounts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"timestamp\" columns from both DataFrames need to be converted to `datetime` objects for ease of use with plotting libraries.\n",
    "\n",
    "Original function to write down timestamp (JS `Date.now()`) uses milliseconds from Unix epoch. We also convert to correct timezone for\n",
    "relevant plots (UTC time not really fun for investigating localized human behaviour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commandCounts['timestamp'] = pd.to_datetime(commandCounts['timestamp'], unit='ms')\n",
    "oldCommandCounts['timestamp'] = pd.to_datetime(oldCommandCounts['timestamp'], unit='ms')\n",
    "\n",
    "commandCounts['timestamp'] = commandCounts['timestamp'].dt.tz_localize('UTC').dt.tz_convert('America/Los_Angeles')\n",
    "oldCommandCounts['timestamp'] = oldCommandCounts['timestamp'].dt.tz_localize('UTC').dt.tz_convert('America/Los_Angeles')\n",
    "\n",
    "commandCounts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we'll concatenate the two DataFrames in a separate variable to have full information for simple command count analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatCounts = pd.concat([oldCommandCounts, commandCounts])\n",
    "\n",
    "concatCounts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contest Results\n",
    "\n",
    "Initially, a competition was announced to see which command would have the most runs after two weeks. The simplest way to display these results is using a bar chart. We'll use a horizontal bar chart to list the results. Bars will represent command count, sorted in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "competitionResult = sns.countplot(y='command', data=concatCounts, order=concatCounts['command'].value_counts().index)\n",
    "\n",
    "for p in competitionResult.patches:\n",
    "    x = p.get_x() + (p.get_width() / 1.02) # move labels to the left in bar proportionally\n",
    "    y = p.get_y() + (p.get_height() / 2.)  # center label on bar\n",
    "    value = int(p.get_width())\n",
    "    # Annotate value on x and y we calculated before\n",
    "    competitionResult.text(x, y, value, ha=\"right\", va='center', color='white')\n",
    "\n",
    "plt.xlabel('Number of times run')\n",
    "plt.ylabel('Command')\n",
    "plt.title('Command Counts - All Commands')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of commands run by user per commands\n",
    "\n",
    "Some commands were more evenly called than others. We want to see the distribution of calls for each top command.\n",
    "\n",
    "First, for each graph, we'll filter command and aggregate by member. Then, we simply bar plot the counts into separate figures for each command.\n",
    "Since subplots make all the plots look really bad (too low resolution), separate figures are plotted and then saved to files. We'll display an\n",
    "example figure that comes out of this plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for command in commandCounts['command'].unique():\n",
    "    fig = plt.figure(dpi=300)\n",
    "\n",
    "    filteredCommandCounts = commandCounts.query(\"command == '\" + command + \"'\")\n",
    "    numberOfUserCallsOfCommand = sns.countplot(y='username', data=filteredCommandCounts, order=filteredCommandCounts['username'].value_counts().index)\n",
    "\n",
    "    for p in numberOfUserCallsOfCommand.patches:\n",
    "        x = p.get_x() + (p.get_width() / 1.02)   # move labels to the left in bar proportionally\n",
    "        y = p.get_y() + (p.get_height() / 1.75)  # center label on bar\n",
    "        value = int(p.get_width())\n",
    "        if value == 1:\n",
    "            # We don't want to annotate any bar with value \"1\", since\n",
    "            # most charts end up being really small.\n",
    "            continue\n",
    "        numberOfUserCallsOfCommand.text(x, y, value, ha=\"right\", va='center', color='white')\n",
    "    plt.xlabel('Number of times run')\n",
    "    plt.ylabel('Username')\n",
    "    plt.title('Command Call Distribution by User - /' + command)\n",
    "    plt.savefig('outputs/commandDistribution-' + command + '.png', bbox_inches='tight')\n",
    "    plt.savefig('outputs/commandDistribution-' + command + '.svg', bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Plot for /bread](outputs/commandDistribution-bread.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak times for commands\n",
    "\n",
    "Members of ACM are more active on Discord at different times from one another. Sadly, tracking the number of commands is not perfectly geniune\n",
    "to activity on the server (not all users use BreadBot's commands often), but we'll try this for now. We'll do full message data later.\n",
    "\n",
    "Firstly, we'll take the existing dataset and split the timestamp column into day of week and hour of day.\n",
    "This will let us plot a heatmap of the schedule over a weekly schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commandCounts['Weekday'] = commandCounts['timestamp'].dt.strftime('%A') # full weekday\n",
    "commandCounts['hour'] = commandCounts['timestamp'].dt.strftime('%-I %p')  # example: 12 AM\n",
    "commandCounts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate the heatmap. We want it to look like a calendar, so it's intuitive. We'll list weekdays horizontally, and times vertically.\n",
    "\n",
    "We'll set up the pivot table accordingly and Seaborn will do the rest. (Yay!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need these because Pandas sorts the index alphabetically, but that's not the same\n",
    "# as actual chronological order. We use these sample lists to sort the index and columns\n",
    "# properly.\n",
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "hours = ['12 AM', '1 AM', '2 AM', '3 AM', '4 AM', '5 AM', '6 AM', '7 AM', '8 AM', '9 AM', '10 AM', '11 AM',\n",
    "         '12 PM', '1 PM', '2 PM', '3 PM', '4 PM', '5 PM', '6 PM', '7 PM', '8 PM', '9 PM', '10 PM', '11 PM']\n",
    "\n",
    "commandTimes = pd.crosstab(commandCounts['hour'], commandCounts['Weekday'])\n",
    "[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']]\n",
    "commandTimes = commandTimes.reindex(days, axis=\"columns\") # sort days\n",
    "commandTimes = commandTimes.reindex(hours, axis=\"rows\", fill_value = 0) # sort hours\n",
    "\n",
    "commandTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = sns.heatmap(commandTimes, cmap='Blues')\n",
    "plt.xlabel('Weekday')\n",
    "plt.ylabel('Hour of day')\n",
    "plt.title('Command Distribution by Time and Date')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak chat times using DiscordChatExporter\n",
    "\n",
    "Since not everyone uses BreadBot commands as much as others (data points to biases of singular members abusing specific commands),\n",
    "we'll attempt the same heatmap using more relevant data.\n",
    "\n",
    "We can use Discord Chat Exporter to extract messages across all channels of a guild. After doing so, we may import the values\n",
    "into the notebook and run the same procedure as for the previous heatmap, except using full message data.\n",
    "\n",
    "To run DiscordChatExporter and extract all messages from the channels of a guild, I used the following command (assume environment variables are set according to [DiscordChatExporter wiki](https://github.com/Tyrrrz/DiscordChatExporter/wiki/Docker-usage-instructions) or manually):\n",
    "\n",
    "```bash\n",
    "docker run --rm -it -v $PWD:/app/out tyrrrz/discordchatexporter:stable exportguild -g $GUILD_ID --dateformat \"u\" -t $DISCORD_TOKEN -f Csv\n",
    "```\n",
    "\n",
    "Once all chats are successfuly exported, we can firstly concatenate all of the messages at first (we're not interested in anything else but times\n",
    "of messages), and begin santizing for the heatmap, similarly to what we did with the command data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "discordChatLogs = glob.glob(os.path.join(\".\", \"discordChats\", \"*.csv\")) # Get list of all files with \".csv\" at the end\n",
    "\n",
    "chatMessages = pd.concat((pd.read_csv(log) for log in discordChatLogs)) # Read each file\n",
    "chatMessages.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatMessages['Date'] = pd.to_datetime(chatMessages['Date'], utc=True).dt.tz_convert('America/Los_Angeles')\n",
    "chatMessages.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatMessages['Weekday'] = chatMessages['Date'].dt.strftime('%A') # full weekday\n",
    "chatMessages['Hour'] = chatMessages['Date'].dt.strftime('%-I %p')  # example: 12 AM\n",
    "chatMessages.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "hours = ['12 AM', '1 AM', '2 AM', '3 AM', '4 AM', '5 AM', '6 AM', '7 AM', '8 AM', '9 AM', '10 AM', '11 AM',\n",
    "         '12 PM', '1 PM', '2 PM', '3 PM', '4 PM', '5 PM', '6 PM', '7 PM', '8 PM', '9 PM', '10 PM', '11 PM']\n",
    "\n",
    "messageTimes = pd.crosstab(chatMessages['Hour'], chatMessages['Weekday'])\n",
    "messageTimes = messageTimes.reindex(days, axis=\"columns\")\n",
    "messageTimes = messageTimes.reindex(hours, axis=\"rows\", fill_value = 0)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "sns.heatmap(messageTimes, cmap='Blues')\n",
    "plt.xlabel('Weekday')\n",
    "plt.ylabel('Hour of day')\n",
    "plt.title('All-Time Message Distribution by Time and Date')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These heatmaps can also be refined to only include specific users' messages by merely querying for the users. Below we have an example of the same graph, but for myself. You can try different users from the guild by changing the `author` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "hours = ['12 AM', '1 AM', '2 AM', '3 AM', '4 AM', '5 AM', '6 AM', '7 AM', '8 AM', '9 AM', '10 AM', '11 AM',\n",
    "         '12 PM', '1 PM', '2 PM', '3 PM', '4 PM', '5 PM', '6 PM', '7 PM', '8 PM', '9 PM', '10 PM', '11 PM']\n",
    "author = 'Storm_FireFox1#0001' # Change this. You probably want to put in username and tag\n",
    "\n",
    "queriedMessages = chatMessages.query(f\"Author == '{author}'\") # Filter out any message not by author\n",
    "\n",
    "userMessageTimes = pd.crosstab(queriedMessages['Hour'], queriedMessages['Weekday'])\n",
    "userMessageTimes = userMessageTimes.reindex(days, axis=\"columns\")\n",
    "userMessageTimes = userMessageTimes.reindex(hours, axis=\"rows\", fill_value = 0)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "sns.heatmap(userMessageTimes, cmap='Blues')\n",
    "plt.xlabel('Weekday')\n",
    "plt.ylabel('Hour of day')\n",
    "plt.title('All-Time Message Distribution for User by Time and Date - ' + author)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the spike in the all-time distribution at around 11 PM. We will investigate by looking at the data directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 PM Spike\n",
    "\n",
    "I think looking at the most common words to appear during that time in messages will shed light on the spike mystery.\n",
    "\n",
    "We begin by filtering all messages to only look at those on wednesdays at 11 PM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikeMessages = chatMessages.query(\"Weekday == 'Wednesday' and Hour == '11 PM'\")\n",
    "spikeMessages.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll continue by grouping the messages by date. This will at least give us a view of what was the longest conversation during that time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikeMessages['daydate'] = spikeMessages['Date'].dt.strftime(\"%d-%m-%Y\")\n",
    "spikeMessages['daydate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data directly, we notice a very specific conversation taking place on the provided date, which was internal to board. I will exclude details about the conversation at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikeMessages = spikeMessages.query(\"daydate == '27-05-2020'\")\n",
    "spikeMessages.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Member Growth\n",
    "\n",
    "We'll also look at how the Discord server has grown over time by looking at amount of messages by month. (i.e. amount of activity by month)\n",
    "\n",
    "Afterwards, we create a simple bar plot. We'll exclude June, since the month is not over yet. (as of time of writing and extraction of dataset)\n",
    "Additionally, we'll disable sorting, as this messes up the sorting of the dates we've done before (alphabetical sort != chronological order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatMessages['month'] = chatMessages['Date'].dt.strftime('%b %Y')\n",
    "chatMessages = chatMessages.sort_values(by='Date')\n",
    "countByMonth = chatMessages['month'].value_counts().reindex(chatMessages['month'].unique())\n",
    "\n",
    "countByMonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "sns.lineplot(data=countByMonth.drop('Jun 2020'), sort=False)\n",
    "plt.title('Amount of Messages by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('# of messages')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bitc011c7a706a240cc96791965ea64714d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}